{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation: Data Pre-Processing\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\20191678\\AppData\\Local\\anaconda3\\envs\\ITP\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.3.0\n",
      "Numpy version: 1.26.4\n",
      "Pytorch version: 2.2.1\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 865972f7a791bf7b42efbcd87c8402bd865b329e\n",
      "MONAI __file__: c:\\Users\\<username>\\AppData\\Local\\anaconda3\\envs\\ITP\\Lib\\site-packages\\monai\\__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.11\n",
      "ITK version: 5.3.0\n",
      "Nibabel version: 5.2.1\n",
      "scikit-image version: 0.22.0\n",
      "scipy version: 1.12.0\n",
      "Pillow version: 10.2.0\n",
      "Tensorboard version: 2.16.2\n",
      "gdown version: 4.7.3\n",
      "TorchVision version: 0.17.1\n",
      "tqdm version: 4.66.2\n",
      "lmdb version: 1.4.1\n",
      "psutil version: 5.9.8\n",
      "pandas version: 2.2.1\n",
      "einops version: 0.7.0\n",
      "transformers version: 4.38.2\n",
      "mlflow version: 2.11.1\n",
      "pynrrd version: 1.0.0\n",
      "clearml version: 1.14.5rc0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from monai.data import DataLoader\n",
    "from monai.transforms import (EnsureChannelFirstd,\n",
    "Compose, LoadImaged, ResampleToMatchd, MapTransform, SaveImaged, LoadImage)\n",
    "\n",
    "from monai.apps import TciaDataset\n",
    "from monai.apps.auto3dseg import AutoRunner\n",
    "from monai.bundle import ConfigParser\n",
    "\n",
    "from monai.config import print_config\n",
    "import json\n",
    "\n",
    "import dicom2nifti\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pydicom\n",
    "\n",
    "print_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-18 12:54:50,329 - INFO - Expected md5 is None, skip md5 check for file ..\\data\\HCC-TACE-Seg\\1.2.276.0.7230010.3.1.3.8323329.41.1604860085.518229.zip.\n",
      "2024-03-18 12:54:50,329 - INFO - File exists: ..\\data\\HCC-TACE-Seg\\1.2.276.0.7230010.3.1.3.8323329.41.1604860085.518229.zip, skipped downloading.\n",
      "2024-03-18 12:54:50,335 - INFO - Writing into directory: ..\\data\\HCC-TACE-Seg\\raw\\1.2.276.0.7230010.3.1.3.8323329.41.1604860085.518229.\n",
      "2024-03-18 12:54:50,965 - INFO - Expected md5 is None, skip md5 check for file ..\\data\\HCC-TACE-Seg\\1.3.6.1.4.1.14519.5.2.1.1706.8374.172517341095680731665822868712.zip.\n",
      "2024-03-18 12:54:50,965 - INFO - File exists: ..\\data\\HCC-TACE-Seg\\1.3.6.1.4.1.14519.5.2.1.1706.8374.172517341095680731665822868712.zip, skipped downloading.\n",
      "2024-03-18 12:54:50,981 - INFO - Writing into directory: ..\\data\\HCC-TACE-Seg\\HCC_017\\300\\image.\n",
      "2024-03-18 12:54:51,265 - INFO - Expected md5 is None, skip md5 check for file ..\\data\\HCC-TACE-Seg\\1.2.276.0.7230010.3.1.3.8323329.2087.1600929091.391108.zip.\n",
      "2024-03-18 12:54:51,265 - INFO - File exists: ..\\data\\HCC-TACE-Seg\\1.2.276.0.7230010.3.1.3.8323329.2087.1600929091.391108.zip, skipped downloading.\n",
      "2024-03-18 12:54:51,265 - INFO - Writing into directory: ..\\data\\HCC-TACE-Seg\\raw\\1.2.276.0.7230010.3.1.3.8323329.2087.1600929091.391108.\n",
      "2024-03-18 12:54:51,812 - INFO - Expected md5 is None, skip md5 check for file ..\\data\\HCC-TACE-Seg\\1.3.6.1.4.1.14519.5.2.1.1706.8374.231513034103627633230071228105.zip.\n",
      "2024-03-18 12:54:51,812 - INFO - File exists: ..\\data\\HCC-TACE-Seg\\1.3.6.1.4.1.14519.5.2.1.1706.8374.231513034103627633230071228105.zip, skipped downloading.\n",
      "2024-03-18 12:54:51,812 - INFO - Writing into directory: ..\\data\\HCC-TACE-Seg\\HCC_077\\300\\image.\n"
     ]
    }
   ],
   "source": [
    "# Specify the collection and segmentation type\n",
    "collection, seg_type = \"HCC-TACE-Seg\", \"SEG\"\n",
    "\n",
    "# Create a dictionary to map the labels in the segmentation to the labels in the image\n",
    "label_dict = {'Liver': 0,\n",
    "  'Mass': 1,\n",
    "  'Necrosis': 2,\n",
    "  'Portal vein': 3,\n",
    "  'Abdominal aorta': 4}\n",
    "\n",
    "class UndoOneHotEncoding(MapTransform):\n",
    "    def __init__(self, keys):\n",
    "        super().__init__(keys)\n",
    "\n",
    "    def __call__(self, data):\n",
    "        for key in self.keys:\n",
    "            data[key] = data[key].argmax(dim=0).unsqueeze(0)\n",
    "        return data\n",
    "    \n",
    "# Create a composed transform that loads the image and segmentation, resamples the image to match the segmentation,\n",
    "# and undoes the one-hot encoding of the segmentation\n",
    "transform = Compose(\n",
    "    [\n",
    "        LoadImaged(reader=\"PydicomReader\", keys=[\"image\", \"seg\"], label_dict=label_dict),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"seg\"]),\n",
    "        #ResampleToMatchd(keys=\"image\", key_dst=\"seg\"),\n",
    "        #UndoOneHotEncoding(keys=\"seg\"),\n",
    "        #SaveImaged(keys=\"seg\", output_dir=\"/segmentations\", output_postfix=\"seg\", output_ext=\".dcm\", output_dtype=\"torch.float32\", data_root_dir=\"../data/HCC-TACE-Seg\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a dataset for the training with a validation split\n",
    "train_dataset = TciaDataset(\n",
    "    root_dir=\"../data\",\n",
    "    collection=collection,\n",
    "    section=\"training\",\n",
    "    transform=transform,\n",
    "    download=True,\n",
    "    download_len=2,\n",
    "    seg_type=seg_type,\n",
    "    progress=True,\n",
    "    cache_rate=0.0,\n",
    "    val_frac=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/HCC-TACE-Seg\\HCC_017\\300\\seg\\00000001.dcm\n",
      "2024-03-18 12:31:44,924 INFO image_writer.py:197 - writing: ..\\data\\HCC-TACE-Seg\\HCC_017\\300\\seg\\00000001.dcm\n",
      "../data/HCC-TACE-Seg\\HCC_077\\300\\seg\\00000001.dcm\n",
      "2024-03-18 12:31:47,934 INFO image_writer.py:197 - writing: ..\\data\\HCC-TACE-Seg\\HCC_077\\300\\seg\\00000001.dcm\n"
     ]
    }
   ],
   "source": [
    "from monai.transforms import LoadImage, Transform, SaveImage\n",
    "import pydicom\n",
    "import os\n",
    "import re\n",
    "\n",
    "class UndoOneHotEncoding(Transform):\n",
    "    def __call__(self, img):\n",
    "        return img.argmax(dim=0).unsqueeze(0)\n",
    "\n",
    "# Define the transform\n",
    "loader = LoadImage(reader= \"PydicomReader\", image_only=True, ensure_channel_first=True)\n",
    "undo_one_hot = UndoOneHotEncoding()\n",
    "\n",
    "\n",
    "\n",
    "# Regular expression to match the patient directories\n",
    "patient_dir_pattern = re.compile(r\"HCC_\\d{3}\")\n",
    "data_root = \"../data/HCC-TACE-Seg\"\n",
    "\n",
    "# Iterate over all directories in the dataset\n",
    "for directory in os.listdir(data_root):\n",
    "    # If the directory is a patient directory\n",
    "    if patient_dir_pattern.match(directory):\n",
    "        \n",
    "        patient_seg_dir = os.path.join(data_root, directory, \"300\", \"seg\")\n",
    "        \n",
    "        # Convert the One-Hot-Encoded DICOM segmentations to a single DICOM segmentation\n",
    "        for seg_file in os.listdir(patient_seg_dir):\n",
    "            if seg_file.endswith(\".dcm\"):\n",
    "                seg_path = os.path.join(patient_seg_dir, seg_file)\n",
    "                \n",
    "                # Load the DICOM file\n",
    "                dicom = loader(seg_path)\n",
    "\n",
    "                # Apply the transform to the segmentation\n",
    "                seg = undo_one_hot(dicom)\n",
    "\n",
    "                print(seg_path)\n",
    "                \n",
    "                save_image = SaveImage(output_dir=patient_seg_dir, output_postfix=\"\", output_ext=\".dcm\", output_dtype=\"torch.float32\", separate_folder=False)\n",
    "                save_image(seg, seg_path)\n",
    "                \n",
    "                # Remove the One-Hot-Encoded segmentation\n",
    "                # if not seg_file.endswith(\"_seg.dcm\"):\n",
    "                #     os.remove(seg_path)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a batch of data from the dataloader\n",
    "batch = next(iter(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch2 = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the batch data keys\n",
    "print(batch.keys())\n",
    "\n",
    "# Print the batch data shapes\n",
    "print(batch[\"image\"].shape, batch[\"seg\"].shape)\n",
    "\n",
    "# Print the batch data types\n",
    "print(batch[\"image\"].dtype, batch[\"seg\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Separate the image and segmentation from the batch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m image, seg \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m], batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseg\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Undo the one-hot encoding of the segmentation\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# seg = seg.argmax(dim=1)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# seg = seg.unsqueeze(1)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(image\u001b[38;5;241m.\u001b[39mshape, seg\u001b[38;5;241m.\u001b[39mshape, seg\u001b[38;5;241m.\u001b[39munique())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "# Separate the image and segmentation from the batch\n",
    "image, seg = batch[\"image\"], batch[\"seg\"]\n",
    "\n",
    "# Undo the one-hot encoding of the segmentation\n",
    "# seg = seg.argmax(dim=1)\n",
    "# seg = seg.unsqueeze(1)\n",
    "\n",
    "\n",
    "print(image.shape, seg.shape, seg.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "slice_idx = 60\n",
    "\n",
    "# Sample a slice from the image\n",
    "CT_slice = image[0, 0, :, :, slice_idx]\n",
    "\n",
    "# Get the maximum segmentation class for each pixel in the slice\n",
    "CT_seg_slice = seg[0, 0, :, :, slice_idx]\n",
    "\n",
    "print(CT_slice.shape, CT_seg_slice.shape)\n",
    "\n",
    "# Plot the image and segmentation slice as a subplot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(CT_slice, cmap=\"gray\")\n",
    "axes[0].set_title(\"CT Image\")\n",
    "axes[1].imshow(CT_seg_slice, cmap=\"jet\")\n",
    "axes[1].set_title(\"CT Segmentation\")\n",
    "plt.colorbar(mappable=axes[1].imshow(CT_seg_slice, cmap='jet'), ax=axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup AutoRunner for automatic segmentation model training and hyperparameter finetuning\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a fold key to all the training data\n",
    "train_dataset.datalist = [{**item, 'fold': 0} for item in train_dataset.datalist]\n",
    "\n",
    "# Change \"seg\" to \"label\" in the datalist\n",
    "for item in train_dataset.datalist:\n",
    "    item[\"label\"] = item.pop(\"seg\")\n",
    "\n",
    "# Concatenate the training and test datalists\n",
    "data_list = {\"training\": train_dataset.datalist}\n",
    "\n",
    "datalist_file = \"../auto3dseg_datalist.json\"\n",
    "with open(datalist_file, \"w\") as f:\n",
    "    json.dump(data_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input configuration .yaml file\n",
    "input_config = {\n",
    "    \"name\": \"HCC-TACE-Seg\",\n",
    "    \"task\": \"segmentation\",  \n",
    "    \"modality\": \"CT\", \n",
    "    \"datalist\": \"../auto3dseg_datalist.json\", \n",
    "    \"dataroot\": \"../data\", \n",
    "}\n",
    "\n",
    "config_yaml = \"./auto3dseg_config.yaml\"\n",
    "ConfigParser.export_config_file(input_config, config_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoRunner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m runner \u001b[38;5;241m=\u001b[39m \u001b[43mAutoRunner\u001b[49m(work_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/auto3dseg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39minput_config)\n\u001b[0;32m      2\u001b[0m runner\u001b[38;5;241m.\u001b[39mrun()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AutoRunner' is not defined"
     ]
    }
   ],
   "source": [
    "runner = AutoRunner(work_dir = \"../data/auto3dseg\", input=input_config)\n",
    "runner.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Q2-5LSH0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
