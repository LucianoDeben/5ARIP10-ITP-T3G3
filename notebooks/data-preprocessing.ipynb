{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation: Data Pre-Processing\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.3.0\n",
      "Numpy version: 1.26.4\n",
      "Pytorch version: 2.2.1\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 865972f7a791bf7b42efbcd87c8402bd865b329e\n",
      "MONAI __file__: c:\\Users\\<username>\\AppData\\Local\\anaconda3\\envs\\torch-gpu\\Lib\\site-packages\\monai\\__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "ITK version: 5.3.0\n",
      "Nibabel version: 5.2.1\n",
      "scikit-image version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "scipy version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Pillow version: 10.2.0\n",
      "Tensorboard version: 2.16.2\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.17.1\n",
      "tqdm version: 4.66.2\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.8\n",
      "pandas version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from monai.data import DataLoader\n",
    "from monai.transforms import (EnsureChannelFirstd,\n",
    "Compose, LoadImaged, ResampleToMatchd, MapTransform, SaveImaged, LoadImage)\n",
    "\n",
    "from monai.apps import TciaDataset\n",
    "from monai.apps.auto3dseg import AutoRunner\n",
    "from monai.bundle import ConfigParser\n",
    "\n",
    "from monai.config import print_config\n",
    "import json\n",
    "\n",
    "print_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-18 22:39:31,273 - INFO - Expected md5 is None, skip md5 check for file ..\\data\\HCC-TACE-Seg\\1.2.276.0.7230010.3.1.3.8323329.41.1604860085.518229.zip.\n",
      "2024-03-18 22:39:31,274 - INFO - File exists: ..\\data\\HCC-TACE-Seg\\1.2.276.0.7230010.3.1.3.8323329.41.1604860085.518229.zip, skipped downloading.\n",
      "2024-03-18 22:39:31,274 - INFO - Writing into directory: ..\\data\\HCC-TACE-Seg\\raw\\1.2.276.0.7230010.3.1.3.8323329.41.1604860085.518229.\n",
      "2024-03-18 22:39:31,785 - INFO - Expected md5 is None, skip md5 check for file ..\\data\\HCC-TACE-Seg\\1.3.6.1.4.1.14519.5.2.1.1706.8374.172517341095680731665822868712.zip.\n",
      "2024-03-18 22:39:31,785 - INFO - File exists: ..\\data\\HCC-TACE-Seg\\1.3.6.1.4.1.14519.5.2.1.1706.8374.172517341095680731665822868712.zip, skipped downloading.\n",
      "2024-03-18 22:39:31,785 - INFO - Writing into directory: ..\\data\\HCC-TACE-Seg\\HCC_017\\300\\image.\n",
      "2024-03-18 22:39:32,071 - INFO - Expected md5 is None, skip md5 check for file ..\\data\\HCC-TACE-Seg\\1.2.276.0.7230010.3.1.3.8323329.2087.1600929091.391108.zip.\n",
      "2024-03-18 22:39:32,071 - INFO - File exists: ..\\data\\HCC-TACE-Seg\\1.2.276.0.7230010.3.1.3.8323329.2087.1600929091.391108.zip, skipped downloading.\n",
      "2024-03-18 22:39:32,071 - INFO - Writing into directory: ..\\data\\HCC-TACE-Seg\\raw\\1.2.276.0.7230010.3.1.3.8323329.2087.1600929091.391108.\n",
      "2024-03-18 22:39:32,604 - INFO - Expected md5 is None, skip md5 check for file ..\\data\\HCC-TACE-Seg\\1.3.6.1.4.1.14519.5.2.1.1706.8374.231513034103627633230071228105.zip.\n",
      "2024-03-18 22:39:32,604 - INFO - File exists: ..\\data\\HCC-TACE-Seg\\1.3.6.1.4.1.14519.5.2.1.1706.8374.231513034103627633230071228105.zip, skipped downloading.\n",
      "2024-03-18 22:39:32,604 - INFO - Writing into directory: ..\\data\\HCC-TACE-Seg\\HCC_077\\300\\image.\n",
      "2024-03-18 22:39:34,953 - INFO - Expected md5 is None, skip md5 check for file ..\\data\\HCC-TACE-Seg\\1.2.276.0.7230010.3.1.3.8323329.41.1604860085.518229.zip.\n",
      "2024-03-18 22:39:34,953 - INFO - File exists: ..\\data\\HCC-TACE-Seg\\1.2.276.0.7230010.3.1.3.8323329.41.1604860085.518229.zip, skipped downloading.\n",
      "2024-03-18 22:39:34,953 - INFO - Writing into directory: ..\\data\\HCC-TACE-Seg\\raw\\1.2.276.0.7230010.3.1.3.8323329.41.1604860085.518229.\n",
      "2024-03-18 22:39:35,586 - INFO - Expected md5 is None, skip md5 check for file ..\\data\\HCC-TACE-Seg\\1.3.6.1.4.1.14519.5.2.1.1706.8374.172517341095680731665822868712.zip.\n",
      "2024-03-18 22:39:35,586 - INFO - File exists: ..\\data\\HCC-TACE-Seg\\1.3.6.1.4.1.14519.5.2.1.1706.8374.172517341095680731665822868712.zip, skipped downloading.\n",
      "2024-03-18 22:39:35,586 - INFO - Writing into directory: ..\\data\\HCC-TACE-Seg\\HCC_017\\300\\image.\n",
      "2024-03-18 22:39:35,866 - INFO - Expected md5 is None, skip md5 check for file ..\\data\\HCC-TACE-Seg\\1.2.276.0.7230010.3.1.3.8323329.2087.1600929091.391108.zip.\n",
      "2024-03-18 22:39:35,868 - INFO - File exists: ..\\data\\HCC-TACE-Seg\\1.2.276.0.7230010.3.1.3.8323329.2087.1600929091.391108.zip, skipped downloading.\n",
      "2024-03-18 22:39:35,868 - INFO - Writing into directory: ..\\data\\HCC-TACE-Seg\\raw\\1.2.276.0.7230010.3.1.3.8323329.2087.1600929091.391108.\n",
      "2024-03-18 22:39:36,431 - INFO - Expected md5 is None, skip md5 check for file ..\\data\\HCC-TACE-Seg\\1.3.6.1.4.1.14519.5.2.1.1706.8374.231513034103627633230071228105.zip.\n",
      "2024-03-18 22:39:36,431 - INFO - File exists: ..\\data\\HCC-TACE-Seg\\1.3.6.1.4.1.14519.5.2.1.1706.8374.231513034103627633230071228105.zip, skipped downloading.\n",
      "2024-03-18 22:39:36,431 - INFO - Writing into directory: ..\\data\\HCC-TACE-Seg\\HCC_077\\300\\image.\n"
     ]
    }
   ],
   "source": [
    "# Specify the collection and segmentation type\n",
    "collection, seg_type = \"HCC-TACE-Seg\", \"SEG\"\n",
    "\n",
    "# Create a dictionary to map the labels in the segmentation to the labels in the image\n",
    "label_dict = {'Liver': 0,\n",
    "  'Mass': 1,\n",
    "  'Necrosis': 2,\n",
    "  'Portal vein': 3,\n",
    "  'Abdominal aorta': 4}\n",
    "\n",
    "class UndoOneHotEncoding(MapTransform):\n",
    "    def __init__(self, keys):\n",
    "        super().__init__(keys)\n",
    "\n",
    "    def __call__(self, data):\n",
    "        for key in self.keys:\n",
    "            data[key] = data[key].argmax(dim=0).unsqueeze(0)\n",
    "        return data\n",
    "    \n",
    "# Create a composed transform that loads the image and segmentation, resamples the image to match the segmentation,\n",
    "# and undoes the one-hot encoding of the segmentation\n",
    "transform = Compose(\n",
    "    [\n",
    "        LoadImaged(reader=\"PydicomReader\", keys=[\"image\", \"seg\"], label_dict=label_dict),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"seg\"]),\n",
    "        #ResampleToMatchd(keys=\"image\", key_dst=\"seg\"),\n",
    "        #UndoOneHotEncoding(keys=\"seg\"),\n",
    "        #SaveImaged(keys=\"seg\", output_dir=\"/segmentations\", output_postfix=\"seg\", output_ext=\".dcm\", output_dtype=\"torch.float32\", data_root_dir=\"../data/HCC-TACE-Seg\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a dataset for the training with a validation split\n",
    "train_dataset = TciaDataset(\n",
    "    root_dir=\"../data\",\n",
    "    collection=collection,\n",
    "    section=\"training\",\n",
    "    transform=transform,\n",
    "    download=True,\n",
    "    download_len=2,\n",
    "    seg_type=seg_type,\n",
    "    progress=True,\n",
    "    cache_rate=0.0,\n",
    "    val_frac=0.0,\n",
    "    seed=0,\n",
    ")\n",
    "\n",
    "# Create a dataset for the training with a validation split\n",
    "test_dataset = TciaDataset(\n",
    "    root_dir=\"../data\",\n",
    "    collection=collection,\n",
    "    section=\"test\",\n",
    "    transform=transform,\n",
    "    download=True,\n",
    "    download_len=2,\n",
    "    seg_type=seg_type,\n",
    "    progress=True,\n",
    "    cache_rate=0.0,\n",
    "    val_frac=0.0,\n",
    "    seed=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import LoadImage, Transform, SaveImage\n",
    "import pydicom\n",
    "import os\n",
    "import re\n",
    "\n",
    "class UndoOneHotEncoding(Transform):\n",
    "    def __call__(self, img):\n",
    "        return img.argmax(dim=0).unsqueeze(0)\n",
    "\n",
    "# Define the transform\n",
    "loader = LoadImage(reader= \"PydicomReader\", image_only=True, ensure_channel_first=True)\n",
    "undo_one_hot = UndoOneHotEncoding()\n",
    "\n",
    "\n",
    "\n",
    "# Regular expression to match the patient directories\n",
    "patient_dir_pattern = re.compile(r\"HCC_\\d{3}\")\n",
    "data_root = \"../data/HCC-TACE-Seg\"\n",
    "\n",
    "# Iterate over all directories in the dataset\n",
    "for directory in os.listdir(data_root):\n",
    "    # If the directory is a patient directory\n",
    "    if patient_dir_pattern.match(directory):\n",
    "        \n",
    "        patient_seg_dir = os.path.join(data_root, directory, \"300\", \"seg\")\n",
    "        \n",
    "        # Convert the One-Hot-Encoded DICOM segmentations to a single DICOM segmentation\n",
    "        for seg_file in os.listdir(patient_seg_dir):\n",
    "            if seg_file.endswith(\".dcm\"):\n",
    "                seg_path = os.path.join(patient_seg_dir, seg_file)\n",
    "                \n",
    "                # Load the DICOM file\n",
    "                dicom = loader(seg_path)\n",
    "\n",
    "                # Apply the transform to the segmentation\n",
    "                seg = undo_one_hot(dicom)\n",
    "                \n",
    "                save_image = SaveImage(output_dir=patient_seg_dir, output_postfix=\"\", output_ext=\".dcm\", output_dtype=\"torch.float32\", separate_folder=False)\n",
    "                save_image(seg, seg_path)\n",
    "                \n",
    "                # Remove the One-Hot-Encoded segmentation\n",
    "                # if not seg_file.endswith(\"_seg.dcm\"):\n",
    "                #     os.remove(seg_path)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a batch of data from the dataloader\n",
    "batch = next(iter(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch2 = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the batch data keys\n",
    "print(batch.keys())\n",
    "\n",
    "# Print the batch data shapes\n",
    "print(batch[\"image\"].shape, batch[\"seg\"].shape)\n",
    "\n",
    "# Print the batch data types\n",
    "print(batch[\"image\"].dtype, batch[\"seg\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the image and segmentation from the batch\n",
    "image, seg = batch[\"image\"], batch[\"seg\"]\n",
    "\n",
    "# Undo the one-hot encoding of the segmentation\n",
    "# seg = seg.argmax(dim=1)\n",
    "# seg = seg.unsqueeze(1)\n",
    "\n",
    "\n",
    "print(image.shape, seg.shape, seg.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "slice_idx = 60\n",
    "\n",
    "# Sample a slice from the image\n",
    "CT_slice = image[0, 0, :, :, slice_idx]\n",
    "\n",
    "# Get the maximum segmentation class for each pixel in the slice\n",
    "CT_seg_slice = seg[0, 0, :, :, slice_idx]\n",
    "\n",
    "print(CT_slice.shape, CT_seg_slice.shape)\n",
    "\n",
    "# Plot the image and segmentation slice as a subplot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(CT_slice, cmap=\"gray\")\n",
    "axes[0].set_title(\"CT Image\")\n",
    "axes[1].imshow(CT_seg_slice, cmap=\"jet\")\n",
    "axes[1].set_title(\"CT Segmentation\")\n",
    "plt.colorbar(mappable=axes[1].imshow(CT_seg_slice, cmap='jet'), ax=axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup AutoRunner for automatic segmentation model training and hyperparameter finetuning\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a fold key to all the training data\n",
    "train_dataset.datalist = [{**item, 'fold': 0} for item in train_dataset.datalist]\n",
    "\n",
    "# Change \"seg\" to \"label\" in the datalist\n",
    "for item in train_dataset.datalist:\n",
    "    item[\"label\"] = item.pop(\"seg\")\n",
    "    \n",
    "for item in test_dataset.datalist:\n",
    "    item[\"label\"] = item.pop(\"seg\")\n",
    "\n",
    "# Concatenate the training and test datalists\n",
    "data_list = {\"training\": train_dataset.datalist, \"testing\": test_dataset.datalist}\n",
    "\n",
    "datalist_file = \"../auto3dseg_datalist.json\"\n",
    "with open(datalist_file, \"w\") as f:\n",
    "    json.dump(data_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input configuration .yaml file\n",
    "input_config = {\n",
    "    \"name\": \"HCC-TACE-Seg\",\n",
    "    \"task\": \"segmentation\",  \n",
    "    \"modality\": \"CT\", \n",
    "    \"datalist\": \"../auto3dseg_datalist.json\", \n",
    "    \"dataroot\": \"../data\", \n",
    "}\n",
    "\n",
    "config_yaml = \"../auto3dseg_config.yaml\"\n",
    "ConfigParser.export_config_file(input_config, config_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-18 22:39:52,731 - INFO - AutoRunner using work directory ../data/auto3dseg\n",
      "2024-03-18 22:39:52,740 - INFO - Datalist was copied to work_dir: d:\\Programming\\AI\\5ARIP10-ITP-T3G3\\data\\auto3dseg\\auto3dseg_datalist.json\n",
      "2024-03-18 22:39:52,743 - INFO - Setting num_fold 1 based on the input datalist d:\\Programming\\AI\\5ARIP10-ITP-T3G3\\data\\auto3dseg\\auto3dseg_datalist.json.\n",
      "2024-03-18 22:39:52,751 - INFO - Using user defined command running prefix , will override other settings\n",
      "2024-03-18 22:39:52,752 - INFO - Running data analysis...\n",
      "2024-03-18 22:39:52,753 - INFO - Found 1 GPUs for data analyzing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:22<00:00, 11.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-18 22:40:15,110 - INFO - Data spacing is not completely uniform. MONAI transforms may provide unexpected result\n",
      "2024-03-18 22:40:15,111 - INFO - Writing data stats to d:\\Programming\\AI\\5ARIP10-ITP-T3G3\\data\\auto3dseg\\datastats.yaml.\n",
      "2024-03-18 22:40:15,118 - INFO - Writing by-case data stats to d:\\Programming\\AI\\5ARIP10-ITP-T3G3\\data\\auto3dseg\\datastats_by_case.yaml, this may take a while.\n",
      "2024-03-18 22:40:15,175 - INFO - BundleGen from https://github.com/Project-MONAI/research-contributions/releases/download/algo_templates/249bf4b.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "algo_templates.tar.gz: 104kB [00:00, 167kB/s]                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-18 22:40:15,816 - INFO - Downloaded: C:\\Users\\20191678\\AppData\\Local\\Temp\\tmpdqinw76p\\algo_templates.tar.gz\n",
      "2024-03-18 22:40:15,816 - INFO - Expected md5 is None, skip md5 check for file C:\\Users\\20191678\\AppData\\Local\\Temp\\tmpdqinw76p\\algo_templates.tar.gz.\n",
      "2024-03-18 22:40:15,816 - INFO - Writing into directory: d:\\Programming\\AI\\5ARIP10-ITP-T3G3\\data\\auto3dseg.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-18 22:40:16,199 - INFO - Generated:d:\\Programming\\AI\\5ARIP10-ITP-T3G3\\data\\auto3dseg\\segresnet_0\n",
      "2024-03-18 22:40:16,367 - INFO - Generated:d:\\Programming\\AI\\5ARIP10-ITP-T3G3\\data\\auto3dseg\\segresnet2d_0\n",
      "2024-03-18 22:40:16,528 - INFO - Generated:d:\\Programming\\AI\\5ARIP10-ITP-T3G3\\data\\auto3dseg\\swinunetr_0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\20191678\\AppData\\Local\\anaconda3\\envs\\torch-gpu\\Lib\\logging\\__init__.py:1113\u001b[0m, in \u001b[0;36mStreamHandler.emit\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;66;03m# issue 35046: merged two stream.writes into one.\u001b[39;00m\n\u001b[1;32m-> 1113\u001b[0m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[1;32mc:\\Users\\20191678\\AppData\\Local\\anaconda3\\envs\\torch-gpu\\Lib\\site-packages\\colorama\\ansitowin32.py:47\u001b[0m, in \u001b[0;36mStreamWrapper.write\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__convertor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\20191678\\AppData\\Local\\anaconda3\\envs\\torch-gpu\\Lib\\site-packages\\colorama\\ansitowin32.py:177\u001b[0m, in \u001b[0;36mAnsiToWin32.write\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrip \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert:\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_and_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\20191678\\AppData\\Local\\anaconda3\\envs\\torch-gpu\\Lib\\site-packages\\colorama\\ansitowin32.py:205\u001b[0m, in \u001b[0;36mAnsiToWin32.write_and_convert\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    204\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m end\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_plain_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\20191678\\AppData\\Local\\anaconda3\\envs\\torch-gpu\\Lib\\site-packages\\colorama\\ansitowin32.py:210\u001b[0m, in \u001b[0;36mAnsiToWin32.write_plain_text\u001b[1;34m(self, text, start, end)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;241m<\u001b[39m end:\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapped\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[1;32mc:\\Users\\20191678\\AppData\\Local\\anaconda3\\envs\\torch-gpu\\Lib\\site-packages\\ipykernel\\iostream.py:679\u001b[0m, in \u001b[0;36mOutStream.write\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    678\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI/O operation on closed file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 679\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    681\u001b[0m is_child \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_master_process()\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m runner \u001b[38;5;241m=\u001b[39m AutoRunner(work_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/auto3dseg\u001b[39m\u001b[38;5;124m\"\u001b[39m,train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39minput_config, algos\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegresnet\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegresnet2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mswinunetr\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\20191678\\AppData\\Local\\anaconda3\\envs\\torch-gpu\\Lib\\site-packages\\monai\\apps\\auto3dseg\\auto_runner.py:812\u001b[0m, in \u001b[0;36mAutoRunner.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexport_cache(train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 812\u001b[0m     \u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSkipping algorithm training...\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;66;03m# step 4: model ensemble and write the prediction to disks.\u001b[39;00m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mensemble:\n",
      "File \u001b[1;32mc:\\Users\\20191678\\AppData\\Local\\anaconda3\\envs\\torch-gpu\\Lib\\logging\\__init__.py:1489\u001b[0m, in \u001b[0;36mLogger.info\u001b[1;34m(self, msg, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1480\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;124;03mLog 'msg % args' with severity 'INFO'.\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;124;03mlogger.info(\"Houston, we have a %s\", \"interesting problem\", exc_info=1)\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misEnabledFor(INFO):\n\u001b[1;32m-> 1489\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINFO\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\20191678\\AppData\\Local\\anaconda3\\envs\\torch-gpu\\Lib\\logging\\__init__.py:1634\u001b[0m, in \u001b[0;36mLogger._log\u001b[1;34m(self, level, msg, args, exc_info, extra, stack_info, stacklevel)\u001b[0m\n\u001b[0;32m   1631\u001b[0m         exc_info \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n\u001b[0;32m   1632\u001b[0m record \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakeRecord(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, level, fn, lno, msg, args,\n\u001b[0;32m   1633\u001b[0m                          exc_info, func, extra, sinfo)\n\u001b[1;32m-> 1634\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\20191678\\AppData\\Local\\anaconda3\\envs\\torch-gpu\\Lib\\logging\\__init__.py:1644\u001b[0m, in \u001b[0;36mLogger.handle\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   1637\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1638\u001b[0m \u001b[38;5;124;03mCall the handlers for the specified record.\u001b[39;00m\n\u001b[0;32m   1639\u001b[0m \n\u001b[0;32m   1640\u001b[0m \u001b[38;5;124;03mThis method is used for unpickled records received from a socket, as\u001b[39;00m\n\u001b[0;32m   1641\u001b[0m \u001b[38;5;124;03mwell as those created locally. Logger-level filtering is applied.\u001b[39;00m\n\u001b[0;32m   1642\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisabled) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter(record):\n\u001b[1;32m-> 1644\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallHandlers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\20191678\\AppData\\Local\\anaconda3\\envs\\torch-gpu\\Lib\\logging\\__init__.py:1706\u001b[0m, in \u001b[0;36mLogger.callHandlers\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   1704\u001b[0m     found \u001b[38;5;241m=\u001b[39m found \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1705\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m record\u001b[38;5;241m.\u001b[39mlevelno \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m hdlr\u001b[38;5;241m.\u001b[39mlevel:\n\u001b[1;32m-> 1706\u001b[0m         \u001b[43mhdlr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m c\u001b[38;5;241m.\u001b[39mpropagate:\n\u001b[0;32m   1708\u001b[0m     c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m    \u001b[38;5;66;03m#break out\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\20191678\\AppData\\Local\\anaconda3\\envs\\torch-gpu\\Lib\\logging\\__init__.py:978\u001b[0m, in \u001b[0;36mHandler.handle\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 978\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    980\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\20191678\\AppData\\Local\\anaconda3\\envs\\torch-gpu\\Lib\\logging\\__init__.py:1118\u001b[0m, in \u001b[0;36mStreamHandler.emit\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   1116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m   1117\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m-> 1118\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandleError\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\20191678\\AppData\\Local\\anaconda3\\envs\\torch-gpu\\Lib\\logging\\__init__.py:1031\u001b[0m, in \u001b[0;36mHandler.handleError\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   1029\u001b[0m t, v, tb \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n\u001b[0;32m   1030\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1031\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--- Logging error ---\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1032\u001b[0m     traceback\u001b[38;5;241m.\u001b[39mprint_exception(t, v, tb, \u001b[38;5;28;01mNone\u001b[39;00m, sys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m   1033\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCall stack:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\20191678\\AppData\\Local\\anaconda3\\envs\\torch-gpu\\Lib\\site-packages\\colorama\\ansitowin32.py:47\u001b[0m, in \u001b[0;36mStreamWrapper.write\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__convertor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\20191678\\AppData\\Local\\anaconda3\\envs\\torch-gpu\\Lib\\site-packages\\colorama\\ansitowin32.py:177\u001b[0m, in \u001b[0;36mAnsiToWin32.write\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrip \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert:\n\u001b[1;32m--> 177\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_and_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapped\u001b[38;5;241m.\u001b[39mwrite(text)\n",
      "File \u001b[1;32mc:\\Users\\20191678\\AppData\\Local\\anaconda3\\envs\\torch-gpu\\Lib\\site-packages\\colorama\\ansitowin32.py:205\u001b[0m, in \u001b[0;36mAnsiToWin32.write_and_convert\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_ansi(\u001b[38;5;241m*\u001b[39mmatch\u001b[38;5;241m.\u001b[39mgroups())\n\u001b[0;32m    204\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m end\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_plain_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\20191678\\AppData\\Local\\anaconda3\\envs\\torch-gpu\\Lib\\site-packages\\colorama\\ansitowin32.py:210\u001b[0m, in \u001b[0;36mAnsiToWin32.write_plain_text\u001b[1;34m(self, text, start, end)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_plain_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, start, end):\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;241m<\u001b[39m end:\n\u001b[1;32m--> 210\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapped\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[1;32mc:\\Users\\20191678\\AppData\\Local\\anaconda3\\envs\\torch-gpu\\Lib\\site-packages\\ipykernel\\iostream.py:679\u001b[0m, in \u001b[0;36mOutStream.write\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    678\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI/O operation on closed file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 679\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    681\u001b[0m is_child \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_master_process()\n\u001b[0;32m    682\u001b[0m \u001b[38;5;66;03m# only touch the buffer in the IO thread to avoid races\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file"
     ]
    }
   ],
   "source": [
    "runner = AutoRunner(work_dir = \"../data/auto3dseg\",train=False, input=input_config, algos=[\"segresnet\", \"segresnet2d\", \"swinunetr\"])\n",
    "runner.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Q2-5LSH0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
