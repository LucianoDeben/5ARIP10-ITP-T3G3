{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation: Data Pre-Processing\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from monai.data import DataLoader\n",
    "from monai.transforms import (EnsureChannelFirstd,\n",
    "Compose, LoadImaged, ResampleToMatchd, MapTransform, SaveImaged, LoadImage)\n",
    "\n",
    "from monai.apps import TciaDataset\n",
    "from monai.apps.auto3dseg import AutoRunner\n",
    "from monai.bundle import ConfigParser\n",
    "\n",
    "from monai.config import print_config\n",
    "import json\n",
    "\n",
    "print_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the collection and segmentation type\n",
    "collection, seg_type = \"HCC-TACE-Seg\", \"SEG\"\n",
    "\n",
    "# Create a dictionary to map the labels in the segmentation to the labels in the image\n",
    "label_dict = {'Liver': 0,\n",
    "  'Mass': 1,\n",
    "  'Necrosis': 2,\n",
    "  'Portal vein': 3,\n",
    "  'Abdominal aorta': 4}\n",
    "\n",
    "class UndoOneHotEncoding(MapTransform):\n",
    "    def __init__(self, keys):\n",
    "        super().__init__(keys)\n",
    "\n",
    "    def __call__(self, data):\n",
    "        for key in self.keys:\n",
    "            data[key] = data[key].argmax(dim=0).unsqueeze(0)\n",
    "        return data\n",
    "    \n",
    "# Create a composed transform that loads the image and segmentation, resamples the image to match the segmentation,\n",
    "# and undoes the one-hot encoding of the segmentation\n",
    "transform = Compose(\n",
    "    [\n",
    "        LoadImaged(reader=\"PydicomReader\", keys=[\"image\", \"seg\"], label_dict=label_dict),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"seg\"]),\n",
    "        #ResampleToMatchd(keys=\"image\", key_dst=\"seg\"),\n",
    "        #UndoOneHotEncoding(keys=\"seg\"),\n",
    "        #SaveImaged(keys=\"seg\", output_dir=\"/segmentations\", output_postfix=\"seg\", output_ext=\".dcm\", output_dtype=\"torch.float32\", data_root_dir=\"../data/HCC-TACE-Seg\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a dataset for the training with a validation split\n",
    "train_dataset = TciaDataset(\n",
    "    root_dir=\"../data\",\n",
    "    collection=collection,\n",
    "    section=\"training\",\n",
    "    transform=transform,\n",
    "    download=True,\n",
    "    download_len=2,\n",
    "    seg_type=seg_type,\n",
    "    progress=True,\n",
    "    cache_rate=0.0,\n",
    "    val_frac=0.0,\n",
    "    seed=0,\n",
    ")\n",
    "\n",
    "# Create a dataset for the training with a validation split\n",
    "test_dataset = TciaDataset(\n",
    "    root_dir=\"../data\",\n",
    "    collection=collection,\n",
    "    section=\"test\",\n",
    "    transform=transform,\n",
    "    download=True,\n",
    "    download_len=2,\n",
    "    seg_type=seg_type,\n",
    "    progress=True,\n",
    "    cache_rate=0.0,\n",
    "    val_frac=0.0,\n",
    "    seed=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import LoadImage, Transform, SaveImage\n",
    "import pydicom\n",
    "import os\n",
    "import re\n",
    "\n",
    "class UndoOneHotEncoding(Transform):\n",
    "    def __call__(self, img):\n",
    "        return img.argmax(dim=0).unsqueeze(0)\n",
    "\n",
    "# Define the transform\n",
    "loader = LoadImage(reader= \"PydicomReader\", image_only=True, ensure_channel_first=True)\n",
    "undo_one_hot = UndoOneHotEncoding()\n",
    "\n",
    "\n",
    "\n",
    "# Regular expression to match the patient directories\n",
    "patient_dir_pattern = re.compile(r\"HCC_\\d{3}\")\n",
    "data_root = \"../data/HCC-TACE-Seg\"\n",
    "\n",
    "# Iterate over all directories in the dataset\n",
    "for directory in os.listdir(data_root):\n",
    "    # If the directory is a patient directory\n",
    "    if patient_dir_pattern.match(directory):\n",
    "        \n",
    "        patient_seg_dir = os.path.join(data_root, directory, \"300\", \"seg\")\n",
    "        \n",
    "        # Convert the One-Hot-Encoded DICOM segmentations to a single DICOM segmentation\n",
    "        for seg_file in os.listdir(patient_seg_dir):\n",
    "            if seg_file.endswith(\".dcm\"):\n",
    "                seg_path = os.path.join(patient_seg_dir, seg_file)\n",
    "                \n",
    "                # Load the DICOM file\n",
    "                dicom = loader(seg_path)\n",
    "\n",
    "                # Apply the transform to the segmentation\n",
    "                seg = undo_one_hot(dicom)\n",
    "                \n",
    "                save_image = SaveImage(output_dir=patient_seg_dir, output_postfix=\"\", output_ext=\".dcm\", output_dtype=\"torch.float32\", separate_folder=False)\n",
    "                save_image(seg, seg_path)\n",
    "                \n",
    "                # Remove the One-Hot-Encoded segmentation\n",
    "                # if not seg_file.endswith(\"_seg.dcm\"):\n",
    "                #     os.remove(seg_path)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a batch of data from the dataloader\n",
    "batch = next(iter(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch2 = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the batch data keys\n",
    "print(batch.keys())\n",
    "\n",
    "# Print the batch data shapes\n",
    "print(batch[\"image\"].shape, batch[\"seg\"].shape)\n",
    "\n",
    "# Print the batch data types\n",
    "print(batch[\"image\"].dtype, batch[\"seg\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the image and segmentation from the batch\n",
    "image, seg = batch[\"image\"], batch[\"seg\"]\n",
    "\n",
    "# Undo the one-hot encoding of the segmentation\n",
    "# seg = seg.argmax(dim=1)\n",
    "# seg = seg.unsqueeze(1)\n",
    "\n",
    "\n",
    "print(image.shape, seg.shape, seg.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "slice_idx = 60\n",
    "\n",
    "# Sample a slice from the image\n",
    "CT_slice = image[0, 0, :, :, slice_idx]\n",
    "\n",
    "# Get the maximum segmentation class for each pixel in the slice\n",
    "CT_seg_slice = seg[0, 0, :, :, slice_idx]\n",
    "\n",
    "print(CT_slice.shape, CT_seg_slice.shape)\n",
    "\n",
    "# Plot the image and segmentation slice as a subplot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(CT_slice, cmap=\"gray\")\n",
    "axes[0].set_title(\"CT Image\")\n",
    "axes[1].imshow(CT_seg_slice, cmap=\"jet\")\n",
    "axes[1].set_title(\"CT Segmentation\")\n",
    "plt.colorbar(mappable=axes[1].imshow(CT_seg_slice, cmap='jet'), ax=axes[1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Q2-5LSH0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
