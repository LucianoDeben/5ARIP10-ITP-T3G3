{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation: Segmenation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msvenbbs\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.networks.nets import SwinUNETR\n",
    "from src.preprocessing import get_transforms, get_datasets, get_dataloaders\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "# Set the device\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 43  68   3  74  82  75   6  86  84  79  63  97  90  71  53  27  18  59\n",
      "  89  60  93 103   1  76  42  41   4  15  17  40  38   5  95  54   0  34\n",
      "  28  55  50  11  35  23  52  10  31  78  57  80  91  32  94  14  73  19\n",
      "  29  49 101 102  69  20  98  72  77  25  37  81  46  39  65  58  12  92\n",
      "  88  70  87  36  21  83   9 100  67  64  47  44] [26 61  2 62 85 48 16 99 56 45 66 96 51 13  7 30 22 24 33  8]\n",
      "84 20\n"
     ]
    }
   ],
   "source": [
    "# Get transforms\n",
    "transform = get_transforms()\n",
    "\n",
    "# Get datasets\n",
    "train_ds, val_ds = get_datasets(root_dir=\"../data\", collection=\"HCC-TACE-Seg\", transform=transform, download=False, download_len=1, val_frac=0.2)\n",
    "\n",
    "# Get dataloaders\n",
    "train_loader, val_loader = get_dataloaders(train_ds, val_ds, batch_size=1, num_workers=4)\n",
    "\n",
    "train_dl =train_ds.datalist\n",
    "val_dl = val_ds.datalist\n",
    "\n",
    "\n",
    "# Check length of datasets and dataloaders\n",
    "print(train_ds.get_indices(), val_ds.get_indices())\n",
    "print(len(train_loader), len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 512, 512, 96]) torch.Size([1, 512, 512, 96])\n"
     ]
    }
   ],
   "source": [
    "# Sample a batch of data from the dataloader\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "# Separate the image and segmentation from the batch\n",
    "image, seg = batch[\"image\"], batch[\"seg\"]\n",
    "\n",
    "print(image.shape, seg.shape)\n",
    "\n",
    "#mip, _ = torch.max(seg, dim=-1)\n",
    "#mip = mip.squeeze()\n",
    "#print(mip.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv3DTo2D(\n",
       "  (conv1): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (conv2): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (conv3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5): Conv2d(256, 1, kernel_size=(2, 2), stride=(2, 2))\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import model_source.LRM\n",
    "\n",
    "# Create an instance of the model\n",
    "model = model_source.LRM.Conv3DTo2D()\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256, 256])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(mip[2], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Swin-UNet model\n",
    "#model = SwinUNETR(img_size=(96, 96, 32), in_channels=1, out_channels=1, use_v2 = True, spatial_dims=3, normalize=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sven\\anaconda3\\envs\\torch\\Lib\\site-packages\\monai\\utils\\deprecate_utils.py:221: FutureWarning: monai.networks.nets.swin_unetr SwinUNETR.__init__:img_size: Argument `img_size` has been deprecated since version 1.3. It will be removed in version 1.5. The img_size argument is not required anymore and checks on the input size are run during forward().\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    }
   ],
   "source": [
    "class SwinUNETRSigmoid(nn.Module):\n",
    "    def __init__(self, img_size, in_channels, out_channels, use_v2=True, spatial_dims=3, normalize=False):\n",
    "        super(SwinUNETRSigmoid, self).__init__()\n",
    "        self.model = SwinUNETR(img_size=img_size, in_channels=in_channels, out_channels=out_channels, use_v2=use_v2, spatial_dims=spatial_dims, normalize=normalize)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Create the model instance\n",
    "model = SwinUNETRSigmoid(img_size=(96, 96, 32), in_channels=1, out_channels=1, use_v2=True, spatial_dims=3, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Sven\\Documents\\GitHub\\5ARIP10-ITP-T3G3\\notebooks\\wandb\\run-20240501_112357-pwtscafl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/svenbbs/HCC%20TACE/runs/pwtscafl' target=\"_blank\">test</a></strong> to <a href='https://wandb.ai/svenbbs/HCC%20TACE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/svenbbs/HCC%20TACE' target=\"_blank\">https://wandb.ai/svenbbs/HCC%20TACE</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/svenbbs/HCC%20TACE/runs/pwtscafl' target=\"_blank\">https://wandb.ai/svenbbs/HCC%20TACE/runs/pwtscafl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x0000026BC8A43060>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sven\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"c:\\Users\\Sven\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1443, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"c:\\Users\\Sven\\anaconda3\\envs\\torch\\Lib\\multiprocessing\\process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Sven\\anaconda3\\envs\\torch\\Lib\\multiprocessing\\popen_spawn_win32.py\", line 112, in wait\n",
      "    res = _winapi.WaitForSingleObject(int(self._handle), msecs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacity of 15.99 GiB of which 3.15 GiB is free. Of the allocated memory 11.15 GiB is allocated by PyTorch, and 284.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(seg\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[1;32mc:\\Users\\Sven\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Sven\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m, in \u001b[0;36mSwinUNETRSigmoid.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m----> 8\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(x)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Sven\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Sven\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Sven\\anaconda3\\envs\\torch\\Lib\\site-packages\\monai\\networks\\nets\\swin_unetr.py:325\u001b[0m, in \u001b[0;36mSwinUNETR.forward\u001b[1;34m(self, x_in)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting():\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_input_size(x_in\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:])\n\u001b[1;32m--> 325\u001b[0m hidden_states_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswinViT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m enc0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder1(x_in)\n\u001b[0;32m    327\u001b[0m enc1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder2(hidden_states_out[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Sven\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Sven\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Sven\\anaconda3\\envs\\torch\\Lib\\site-packages\\monai\\networks\\nets\\swin_unetr.py:1067\u001b[0m, in \u001b[0;36mSwinTransformer.forward\u001b[1;34m(self, x, normalize)\u001b[0m\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_v2:\n\u001b[0;32m   1066\u001b[0m     x0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers1c[\u001b[38;5;241m0\u001b[39m](x0\u001b[38;5;241m.\u001b[39mcontiguous())\n\u001b[1;32m-> 1067\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1068\u001b[0m x1_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj_out(x1, normalize)\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_v2:\n",
      "File \u001b[1;32mc:\\Users\\Sven\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Sven\\anaconda3\\envs\\torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Sven\\anaconda3\\envs\\torch\\Lib\\site-packages\\monai\\networks\\nets\\swin_unetr.py:901\u001b[0m, in \u001b[0;36mBasicLayer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    899\u001b[0m hp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(h \u001b[38;5;241m/\u001b[39m window_size[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m*\u001b[39m window_size[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    900\u001b[0m wp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(w \u001b[38;5;241m/\u001b[39m window_size[\u001b[38;5;241m2\u001b[39m])) \u001b[38;5;241m*\u001b[39m window_size[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m--> 901\u001b[0m attn_mask \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m    903\u001b[0m     x \u001b[38;5;241m=\u001b[39m blk(x, attn_mask)\n",
      "File \u001b[1;32mc:\\Users\\Sven\\anaconda3\\envs\\torch\\Lib\\site-packages\\monai\\networks\\nets\\swin_unetr.py:820\u001b[0m, in \u001b[0;36mcompute_mask\u001b[1;34m(dims, window_size, shift_size, device)\u001b[0m\n\u001b[0;32m    818\u001b[0m mask_windows \u001b[38;5;241m=\u001b[39m mask_windows\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    819\u001b[0m attn_mask \u001b[38;5;241m=\u001b[39m mask_windows\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m mask_windows\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 820\u001b[0m attn_mask \u001b[38;5;241m=\u001b[39m \u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_fill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m100.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_fill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_mask\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 4.20 GiB. GPU 0 has a total capacity of 15.99 GiB of which 3.15 GiB is free. Of the allocated memory 11.15 GiB is allocated by PyTorch, and 284.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "\n",
    "wandb_ = True\n",
    "\n",
    "\n",
    "# Set the model to use the GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Set the hyperparameters for training\n",
    "max_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-5\n",
    "val_interval = 1\n",
    "\n",
    "if wandb_:\n",
    "    run = wandb.init(\n",
    "        # Set the project where this run will be logged\n",
    "        project=\"HCC TACE\", name=\"test\",\n",
    "        # Track hyperparameters and run metadata\n",
    "        config={\n",
    "            \"learning_rate\": {learning_rate},\n",
    "            \"epochs\": {max_epochs},\n",
    "            \"Weight decay\": {weight_decay},\n",
    "            \"Batch_size\": {1},\n",
    "        },\n",
    "    )\n",
    "\n",
    "# Set the optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate, weight_decay=weight_decay)\n",
    "loss_function = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Create the training loop\n",
    "\n",
    "# Set the model to training mode\n",
    "model.train()\n",
    "\n",
    "# Iterate over the training data for the specified number of epochs\n",
    "for epoch in range(max_epochs):\n",
    "    for batch in train_loader:\n",
    "        # Extract the image and segmentation from the batch\n",
    "        image, seg = batch[\"image\"].to(device), batch[\"seg\"].to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        pred = model(image).squeeze()\n",
    "        \n",
    "        print(pred.size())\n",
    "        print(seg.size())\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_function(pred, seg)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        if wandb_:\n",
    "            run.log({\"Train loss\": loss.item()})\n",
    "        \n",
    "    # Print the loss for each epoch\n",
    "    print(f\"Epoch [{epoch+1}/{max_epochs}], Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Compute the validation loss\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            image, seg = batch[\"image\"].to(device), batch[\"seg\"].to(device)\n",
    "            pred = model(image).squeeze()\n",
    "            \n",
    "            loss = loss_function(pred, seg)\n",
    "        print(f\"Validation Loss: {loss.item():.4f}\")\n",
    "\n",
    "        if wandb_:\n",
    "            run.log({\"Validation loss\": loss.item()})\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), \"../models/arteries-2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Saving a CT volume tensor to image format (DICOM / NIFTI)\n",
    "#loss_function = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor(10000))\n",
    "\n",
    "\n",
    "# Load the model\n",
    "model.load_state_dict(torch.load(\"../models/arteries-2.pth\"))\n",
    "model.to('cuda')\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Sample a batch of data from the test dataloader to make predictions\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "# Extract the image and segmentation from the batch\n",
    "image, seg = batch[\"image\"].to(device), batch[\"seg\"].to(device).squeeze()\n",
    "\n",
    "# Make predictions on the image\n",
    "output = model(image).squeeze()\n",
    "\n",
    "\n",
    "\n",
    "#MIP\n",
    "#output,_ =torch.max(output, dim = -1)\n",
    "seg,_ = torch.max(seg, dim = -1)\n",
    "\n",
    "# Get the predicted segmentation class for each pixel\n",
    "pred_seg,_ = torch.max(output, dim = -1)\n",
    "\n",
    "\n",
    "# Visualize the image, ground truth segmentation, and predicted segmentation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "slice_idx = 16\n",
    "\n",
    "\n",
    "\n",
    "# Convert the image, ground truth segmentation, and predicted segmentation to NumPy arrays\n",
    "image = image.cpu().detach().numpy()\n",
    "seg = seg.cpu().detach().numpy()\n",
    "pred_seg = pred_seg.cpu().detach().numpy()\n",
    "\n",
    "# Get the first image, ground truth segmentation, and predicted segmentation from the batch\n",
    "image = image[0, 0, :, :, slice_idx]\n",
    "\n",
    "\n",
    "\n",
    "# Plot the image, ground truth segmentation, and predicted segmentation\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow(image, cmap=\"gray\")\n",
    "axes[0].set_title(\"Image\")\n",
    "axes[1].imshow(seg[0], cmap=\"gray\")\n",
    "axes[1].set_title(\"Ground Truth Segmentation\")\n",
    "axes[2].imshow(pred_seg[0], cmap=\"gray\")\n",
    "axes[2].set_title(\"Predicted Segmentation\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "# Extract the image and segmentation from the batch\n",
    "image, seg = batch[\"image\"], batch[\"seg\"].squeeze()\n",
    "mip,_ = torch.max(seg, dim = -1)\n",
    "\n",
    "image = image[0, 0, :, :, 48]\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "colors = [(0, 0, 0, 0), (1, 0, 0, 1)]  # Start with transparent black, end with opaque red\n",
    "cmap_name = 'transparent_red'\n",
    "cm = LinearSegmentedColormap.from_list(cmap_name, colors)\n",
    "ax.imshow(image, cmap=\"gray\")\n",
    "ax.imshow(mip[0], cmap=cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(pred_seg[0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(seg[0].flatten())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
